repartitioning {
  batch {
    only-once = false
  }
  data-characteristics {
    # @todo Take is not used currently.
    backoff-factor = 1.05
    concept-solidarity = 5
    drift-boundary = 0.125
    drift-history-weight = 0.8
    histogram-compaction = 1250
    histogram-scale-boundary = 5000
    histogram-size-boundary = 5000
    take = 1000
  }
  enabled = true
  excess-key-multiplier = 2
  factory = "org.apache.spark.streaming.repartitioning.StreamingRepartitioningTrackerFactory"
  histogram {
    comparision-treshold = 0.01
  }
  # Histograms to be seen before repartitioning decision is made.
  histogram-threshold = 5
  key-histogram {
    # @todo Not used currently.
    truncate = 1000
  }
  # @todo fix in drc RepartitioningTrackerWorker: use repartitioning.batch.only-once instead
  only {
    once = false
  }
  partitioner-factory = "hu.sztaki.drc.partitioner.KeyIsolatorPartitioner.Factory"
  partitioner-tree-depth = 31
  significant-change {
    # TODO Why exactly do we force significant change?
    always-yes = true
    backdoor = false
  }
  streaming {
    decider {
      factory = "org.apache.spark.streaming.repartitioning.decider.NaiveRetentiveStrategyFactory"
    }
    # Whether to force the number of partitions to the total slots available for the application.
    force-slot-size = false
    optimize-parallelism = false
    global-histogram {
      history-size = 5
    }
    per-batch-sampling-rate = 1
    retentive-key {
      weight = 0.0
    }
    retentive-partition {
      weight = 0.0
    }
    run-simulator = false
  }
  throughput {
    interval = 100
    record-bound = 1000
  }
}